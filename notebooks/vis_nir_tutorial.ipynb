{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# VIS/NIR Tutorial \n",
    "\n",
    "For dual VIS/NIR workflows, a visible image is used to identify an image mask for the plant material.\n",
    "The get nir function is used to get the NIR image that matches the VIS image (must be in same folder,\n",
    "with similar naming scheme), then functions are used to size and place the VIS image mask over the NIR image.\n",
    "This allows two workflows to be done at once and also allows plant material to be identified in low-quality images.\n",
    "We do not recommend this approach if there is a lot of plant movement between capture of NIR and VIS images.\n",
    "\n",
    "To run a VIS/NIR workflow over a single VIS image there are two required inputs:\n",
    "\n",
    "1.  **Image:** Images can be processed regardless of what type of VIS camera was used (high-throughput platform, digital camera, cell phone camera).\n",
    "Image processing will work with adjustments if images are well lit and free of background that is similar in color to plant material.  \n",
    "2.  **Output directory:** If debug mode is set to 'print' output images from each intermediate step are produced.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Libraries \n",
    "import cv2\n",
    "from plantcv import plantcv as pcv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class options:\n",
    "    def __init__(self):\n",
    "        self.image = \"img/tutorial_images/vis_nir/VIS_SV_image.jpg\"\n",
    "        self.debug = \"plot\"\n",
    "        self.writeimg= False \n",
    "        self.result = \"vis_nir_tutorial_results.json\"\n",
    "        self.outdir = \".\" # Store the output to the current directory\n",
    "\n",
    "# Get options\n",
    "args = options()\n",
    "\n",
    "# Set debug to the global parameter \n",
    "pcv.params.debug = args.debug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image \n",
    "\n",
    "# Inputs:\n",
    "#   filename - Image file to be read in \n",
    "#   mode - Return mode of image; either 'native' (default), 'rgb', 'gray', or 'csv' \n",
    "img, path, filename = pcv.readimage(filename=args.image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert RGB to HSV and extract the saturation channel\n",
    "\n",
    "# Inputs:\n",
    "#   rgb_img - RGB image data \n",
    "#   channel - Split by 'h' (hue), 's' (saturation), or 'v' (value) channel\n",
    "s = pcv.rgb2gray_hsv(rgb_img=img, channel='s')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Threshold the Saturation image\n",
    "\n",
    "# Inputs:\n",
    "#   gray_img - Grayscale image data \n",
    "#   threshold- Threshold value (between 0-255)\n",
    "#   max_value - Value to apply above threshold (255 = white) \n",
    "#   object_type - 'light' (default) or 'dark'. If the object is lighter than the background then standard threshold is done.\n",
    "#                 If the object is darker than the background then inverse thresholding is done. \n",
    "s_thresh = pcv.threshold.binary(gray_img=s, threshold=50, max_value=255, object_type='light')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median Blur\n",
    "\n",
    "# Inputs: \n",
    "#   gray_img - Grayscale image data \n",
    "#   ksize - Kernel size (integer or tuple), (ksize, ksize) box if integer input,\n",
    "#           (n, m) box if tuple input \n",
    "s_mblur = pcv.median_blur(gray_img=s_thresh, ksize=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert RGB to LAB and extract the blue-yellow channel\n",
    "\n",
    "# Input:\n",
    "#   rgb_img - RGB image data \n",
    "#   channel- Split by 'l' (lightness), 'a' (green-magenta), or 'b' (blue-yellow) channel\n",
    "b = pcv.rgb2gray_lab(rgb_img=img, channel='b')\n",
    "\n",
    "# Threshold the blue-yellow channel image\n",
    "b_thresh = pcv.threshold.binary(gray_img=b, threshold=129, max_value=255, object_type='light')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join the thresholded saturation and blue-yellow images\n",
    "\n",
    "# Inputs: \n",
    "#   bin_img1 - Binary image data to be compared to bin_img2\n",
    "#   bin_img2 - Binary image data to be compared to bin_img1\n",
    "bs = pcv.logical_and(bin_img1=s_mblur, bin_img2=b_thresh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Mask\n",
    "\n",
    "# Inputs:\n",
    "#   img - RGB or grayscale image data \n",
    "#   mask - Binary mask image data \n",
    "#   mask_color - 'white' or 'black' \n",
    "masked = pcv.apply_mask(img=img, mask=bs, mask_color='white')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify objects\n",
    "\n",
    "# Inputs: \n",
    "#   img - RGB or grayscale image data for plotting \n",
    "#   mask - Binary mask used for detecting contours \n",
    "id_objects,obj_hierarchy = pcv.find_objects(img=masked, mask=bs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Region of Interest (ROI) \n",
    "\n",
    "# Inputs: \n",
    "#   img - RGB or grayscale image to plot the ROI on \n",
    "#   x - The x-coordinate of the upper left corner of the rectangle \n",
    "#   y - The y-coordinate of the upper left corner of the rectangle \n",
    "#   h - The height of the rectangle \n",
    "#   w - The width of the rectangle \n",
    "roi1, roi_hierarchy = pcv.roi.rectangle(img=img, x=800, y=450, h=920, w=700)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This image is relatively large, and it's making it so not all sides of the ROI are showing up \n",
    "# when plotted in Jupyter. There is an optional line_thickness parameter in the params class.\n",
    "# Default line_thickness = 5. \n",
    "pcv.params.line_thickness = 10\n",
    "roi1, roi_hierarchy = pcv.roi.rectangle(img=img, x=800, y=450, h=920, w=700)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide which objects to keep\n",
    "\n",
    "# Inputs:\n",
    "#    img            = img to display kept objects\n",
    "#    roi_contour    = contour of roi, output from any ROI function\n",
    "#    roi_hierarchy  = contour of roi, output from any ROI function\n",
    "#    object_contour = contours of objects, output from pcv.find_objects function\n",
    "#    obj_hierarchy  = hierarchy of objects, output from pcv.find_objects function\n",
    "#    roi_type       = 'partial' (default, for partially inside the ROI), 'cutto', or \n",
    "#                     'largest' (keep only largest contour)\n",
    "roi_objects, hierarchy, kept_mask, obj_area = pcv.roi_objects(img=img, roi_contour=roi1, \n",
    "                                                              roi_hierarchy=roi_hierarchy,\n",
    "                                                              object_contour=id_objects,\n",
    "                                                              obj_hierarchy=obj_hierarchy,\n",
    "                                                              roi_type='partial')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object combine the kept objects\n",
    "\n",
    "# Inputs:\n",
    "#   img - RGB or grayscale image data for plotting \n",
    "#   contours - Contour list \n",
    "#   hierarchy - Contour hierarchy array \n",
    "obj, mask = pcv.object_composition(img=img, contours=roi_objects, hierarchy=hierarchy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Analysis ################  \n",
    "  \n",
    "# Find shape properties\n",
    "\n",
    "# Inputs:\n",
    "#   img - RGB or grayscale image data \n",
    "#   obj- Single or grouped contour object\n",
    "#   mask - Binary image mask to use as mask for moments analysis \n",
    "#   label - Optional label parameter, modifies the variable name of observations recorded. (default `label=\"default\"`)filled_img = pcv.morphology.fill_segments(mask=cropped_mask, objects=edge_objects)\n",
    "\n",
    "analysis_image = pcv.analyze_object(img=img, obj=obj, mask=mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for accute vertices \n",
    "\n",
    "# Inputs:\n",
    "#   img - RGB or grayscale image \n",
    "#   obj - A contour of the plant object \n",
    "#   win - The pre and post point distances on which to calculate \n",
    "#            the angle of the focal point on which to calculate \n",
    "#            the angle\n",
    "#   thresh - Threshold to set for acuteness\n",
    "#   sep - The number of contour points to search within for the \n",
    "#         most acute value \n",
    "#   label -Optional label parameter, modifies the variable name of observations recorded. (default `label=\"default\"`)filled_img = pcv.morphology.fill_segments(mask=cropped_mask, objects=edge_objects)\n",
    "\n",
    "acute_points_list = pcv.acute_vertex(img=img, obj=obj, win=30, thresh=25, sep=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can automatically crop an image to a contour \n",
    "\n",
    "# Inputs: \n",
    "#   img - RGB or grayscale image data\n",
    "#   obj - Contour of target object \n",
    "#   padding_x - Padding in the x direction (default padding_x=0)\n",
    "#   padding_y - Padding in the y direction (default padding_y=0)\n",
    "#   color - Either 'black' (default), 'white', or 'image' \n",
    "cropped_img = pcv.auto_crop(img=img, obj=obj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shape properties relative to user boundary line \n",
    "\n",
    "# Inputs:\n",
    "#   img - RGB or grayscale image data \n",
    "#   obj - Single or grouped contour object \n",
    "#   mask - Binary mask of selected contours \n",
    "#   line_position - Position of boundary line (a value of 0 would draw a line \n",
    "#                   through the bottom of the image) \n",
    "#   label - Optional label parameter, modifies the variable name of observations recorded. (default `label=\"default\"`)filled_img = pcv.morphology.fill_segments(mask=cropped_mask, objects=edge_objects)\n",
    "\n",
    "boundary_images_h = pcv.analyze_bound_horizontal(img=img, obj=obj, mask=mask, \n",
    "                                                 line_position=1370)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   img - RGB or grayscale image data \n",
    "#   obj - Single or grouped contour object \n",
    "#   mask - Binary mask of selected contours \n",
    "#   line_position - Position of boundary line (a value of 0 would draw a line \n",
    "#                   through the left of the image) \n",
    "#   label - Optional label parameter, modifies the variable name of observations recorded. (default `label=\"default\"`)filled_img = pcv.morphology.fill_segments(mask=cropped_mask, objects=edge_objects)\n",
    "\n",
    "boundary_images_v = pcv.analyze_bound_vertical(img=img, obj=obj, mask=mask, \n",
    "                                               line_position=1200)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine color properties\n",
    "\n",
    "# Inputs:\n",
    "#   rgb_img - RGB image data\n",
    "#   mask - Binary mask of selected contours \n",
    "#   hist_plot_type - None (default), 'all', 'rgb', 'lab', or 'hsv'\n",
    "#   label - Optional label parameter, modifies the variable name of observations recorded. (default `label=\"default\"`)filled_img = pcv.morphology.fill_segments(mask=cropped_mask, objects=edge_objects)\n",
    "\n",
    "color_histogram = pcv.analyze_color(rgb_img=img, mask=kept_mask, hist_plot_type='all')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next steps are to get the matching NIR image, resize, and place the VIS mask over it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coresult is set within the second jupyter line of code\n",
    "if args.coresult is not None:\n",
    "    nirpath = pcv.get_nir(path,filename)\n",
    "    nir, path1, filename1 = pcv.readimage(nirpath, mode='gray')\n",
    "\n",
    "# Inputs:\n",
    "#   img - RGB or grayscale image to resize\n",
    "#   resize_x - resize number in the x dimension\n",
    "#   resize_y - resize number in the y dimension \n",
    "nmask = pcv.resize(img=mask, resize_x=0.28, resize_y=0.28)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   img - RGB or grayscale image data \n",
    "#   mask - Binary image to be used as a mask \n",
    "#   x - Amount to push in the vertical direction\n",
    "#   y - Amount to push in the horizontal direction\n",
    "#   v_pos - Push from the 'top' (default) or 'bottom' in the vertical direction\n",
    "#   h_pos - Push from the 'right' (default) or 'left' in the horizontal direction \n",
    "newmask = pcv.crop_position_mask(img=nir, mask=nmask, x=34, y=7, \n",
    "                                 v_pos=\"top\", h_pos=\"right\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find objects in the new mask \n",
    "nir_objects, nir_hierarchy = pcv.find_objects(img=nir, mask=newmask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine objects\n",
    "nir_combined, nir_combinedmask = pcv.object_composition(img=nir, contours=nir_objects, \n",
    "                                                        hierarchy=nir_hierarchy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This image is relatively small now, and the lines drawn are too thick \n",
    "# when plotted in Jupyter. There is an optional line_thickness parameter in the params class.\n",
    "# Default line_thickness = 5. \n",
    "pcv.params.line_thickness = 3\n",
    "\n",
    "nir_combined, nir_combinedmask = pcv.object_composition(img=nir, contours=nir_objects, \n",
    "                                                        hierarchy=nir_hierarchy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the NIR intensity \n",
    "\n",
    "# Inputs: \n",
    "#   gray_img - 8 or 16-bit grayscale image data \n",
    "#   mask - Binary mask made from selected contours \n",
    "#   bins - Number of classes to divide spectrum into\n",
    "#   histplot - If True then plots histogram of intensity values, (default False) \n",
    "#   label - Optional label parameter, modifies the variable name of observations recorded. (default `label=\"default\"`)filled_img = pcv.morphology.fill_segments(mask=cropped_mask, objects=edge_objects)\n",
    "\n",
    "nir_hist = pcv.analyze_nir_intensity(gray_img=nir, mask=nir_combinedmask, \n",
    "                                     bins=256, histplot=True, label=\"NIR\")\n",
    "\n",
    "# If histplot=True then nir_hist contains the histogram plot. Otherwise it is an empty list. \n",
    "# Print out the nir histogram to save it.  \n",
    "pcv.print_image(img=nir_hist, filename='vis_nir_tutorial_nir_hist.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the shape of the object \n",
    "nir_images = pcv.analyze_object(img=nir, obj=nir_combined, mask=nir_combinedmask, label=\"NIR\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The print_results function will take the measurements stored when running any (or all) of these functions, format, \n",
    "# and print an output text file for data analysis. The Outputs class stores data whenever any of the following functions\n",
    "# are ran: analyze_bound_horizontal, analyze_bound_vertical, analyze_color, analyze_nir_intensity, analyze_object, \n",
    "# fluor_fvfm, report_size_marker_area, watershed. If no functions have been run, it will print an empty text file \n",
    "pcv.print_results(filename=args.result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view and/or download the text file output (saved in JSON format)...\n",
    "1) To see the text file with data that got saved out, click “File” tab in top left corner.\n",
    "2) Click “Open…”\n",
    "3) Open the file named “vis_nir_tutorial_results.txt”\n",
    "\n",
    "Check out documentation on how to [convert JSON](https://plantcv.readthedocs.io/en/latest/tools/#convert-output-json-data-files-to-csv-tables) format output into table formatted output. Depending on the analysis steps a PlantCV user may have two CSV files (single value traits and multivalue traits). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
