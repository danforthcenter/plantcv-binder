{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Multi-Plant Tutorial \n",
    "\n",
    "For multi-plant workflows, images with multiple plants are processed and result in individual pictures for each plant, allowing a secondary workflow\n",
    "(see [VIS tutorial](vis_tutorial.ipynb) for example) to be used.\n",
    "The challenge of multi-plant processing is that a single plant can be composed of several contours, therefore contours need to be sorted and clustered together in some way.\n",
    "There are several functions that help with multi-plant image processing. First, the current clustering functions work by asking the user to provide an approximation of the number of desired\n",
    "'rows' and 'columns' that they would like to split the image into. There does not need to be a plant in each spot, but the grid is used as an approximate region to cluster contours within.\n",
    "The [rotation](https://plantcv.readthedocs.io/en/latest/rotate2/) and [shift](https://plantcv.readthedocs.io/en/latest/shift/) functions allow the image to be moved to optimize accurate clustering. Major assumptions that are made are that plants grow but\n",
    "that the imaging position does not change drastically.\n",
    "Also, the clustering functions will not work properly once plants start overlapping, since contours would also start overlapping.\n",
    "\n",
    "To run a multi-plant workflow over a single VIS image there are two required inputs:\n",
    "\n",
    "1.  **Image:** Images can be processed regardless of what type of VIS camera was used (high-throughput platform, digital camera, cell phone camera).\n",
    "Image processing will work with adjustments if images are well lit and free of background that is similar in color to plant material.  \n",
    "2.  **Output directory:** If debug mode is set to 'print' output images from each step are produced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries \n",
    "import numpy as np\n",
    "from plantcv import plantcv as pcv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class options:\n",
    "    def __init__(self):\n",
    "        self.image = \"img/tutorial_images/multi_plant/original_image.jpg\"\n",
    "        self.debug = \"plot\"\n",
    "        self.writeimg= False \n",
    "        self.result = \"./multi_plant_tutorial_results\"\n",
    "        self.outdir = \".\" # Store the output to the current directory \n",
    "\n",
    "# Get options\n",
    "args = options()\n",
    "\n",
    "# Set debug to the global parameter \n",
    "pcv.params.debug = args.debug\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image\n",
    "\n",
    "# Inputs:\n",
    "#   filename - Image file to be read in \n",
    "#   mode - How to read in the image; either 'native' (default), 'rgb', 'gray', or 'csv'\n",
    "img, path, filename = pcv.readimage(filename=args.image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if this is a night image, for some of these dataset's images were captured\n",
    "# at night, even if nothing is visible. To make sure that images are not taken at\n",
    "# night we check that the image isn't mostly dark (0=black, 255=white).\n",
    "# if it is a night image it throws a fatal error and stops the workflow.\n",
    "\n",
    "if np.average(img) < 50:\n",
    "    pcv.fatal_error(\"Night Image\")\n",
    "else:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the white color so you can later\n",
    "# compare color between images.\n",
    "\n",
    "# Inputs:\n",
    "#   img = image object, RGB color space\n",
    "#   roi = region for white reference, if none uses the whole image,\n",
    "#         otherwise (x position, y position, box width, box height)\n",
    "\n",
    "# white balance image based on white toughspot\n",
    "img1 = pcv.white_balance(img, roi=(52,100,20,20))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rotate the image slightly so the plants line up with \n",
    "# the grid that we'll add in a later step\n",
    "\n",
    "# Inputs:\n",
    "#   img = image object, RGB color space\n",
    "#   rotation_deg = Rotation angle in degrees, can be negative, positive values \n",
    "#                  will move counter-clockwise \n",
    "#   crop = If True then image will be cropped to orginal image dimensions, if False\n",
    "#          the image size will be adjusted to accommodate new image dimensions \n",
    "rotate_img = pcv.rotate(img=img1, rotation_deg=-1, crop=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift image. This step is important for clustering later on.\n",
    "# For this image it also allows you to push the green raspberry pi camera\n",
    "# out of the image. This step might not be necessary for all images.\n",
    "# The resulting image is the same size as the original.\n",
    "\n",
    "# Inputs:\n",
    "#   img    = image object\n",
    "#   number = integer, number of pixels to move image\n",
    "#   side   = direction to move from \"top\", \"bottom\", \"right\",\"left\"\n",
    "shift1 = pcv.shift_img(img=img1, number=40, side='top')\n",
    "img1 = shift1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally, one could use the `pcv.flip` function that flips an image in either the \n",
    "# horizontal or vertical direction\n",
    "\n",
    "# Inputs:\n",
    "#   img   = RGB or grayscale image data \n",
    "#   direction = The direction you want the image flipped, either 'horizontal' or 'vertical' \n",
    "flipped_img = pcv.flip(img=img, direction='vertical')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert image from RGB color space to LAB color space\n",
    "# Keep only the green-magenta channel (grayscale)\n",
    "\n",
    "# Inputs:\n",
    "#    rgb_img = image object, RGB color space\n",
    "#    channel = color subchannel ('l' = lightness, 'a' = green-magenta , 'b' = blue-yellow)\n",
    "a = pcv.rgb2gray_lab(rgb_img=img1, channel='a')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set a binary threshold on the saturation channel image\n",
    "\n",
    "# Inputs:\n",
    "#    gray_img    = img object, grayscale\n",
    "#    threshold   = threshold value (0-255)\n",
    "#    max_value   = value to apply above threshold (usually 255 = white)\n",
    "#    object_type = light or dark\n",
    "#       - If object is light then standard thresholding is done\n",
    "#       - If object is dark then inverse thresholding is done\n",
    "img_binary = pcv.threshold.binary(gray_img=a, threshold=120, max_value=255, object_type='dark')\n",
    "#                                                        ^\n",
    "#                                                        |\n",
    "#                                         adjust this value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in small objects (speckles)\n",
    "\n",
    "# Inputs:\n",
    "#    bin_img  = binary image. img will be returned after filling\n",
    "#    size     = minimum object area size in pixels (integer)\n",
    "fill_image = pcv.fill(bin_img=img_binary, size=10)\n",
    "#                                                ^\n",
    "#                                                |\n",
    "#                                 adjust this value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dilate so that you don't lose leaves (just in case)\n",
    "\n",
    "# Inputs:\n",
    "#    gray_img = input image\n",
    "#    ksize    = integer, kernel size\n",
    "#    i        = iterations, i.e. number of consecutive filtering passes\n",
    "dilated = pcv.dilate(gray_img=fill_image, ksize=2, i=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find objects (contours: black-white boundaries)\n",
    "\n",
    "# Inputs:\n",
    "#    img  = image that the objects will be overlayed\n",
    "#    mask = what is used for object detection\n",
    "id_objects, obj_hierarchy = pcv.find_objects(img=img1, mask=dilated)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define region of interest (ROI)\n",
    "\n",
    "# Inputs:\n",
    "#    img   = An RGB or grayscale image to plot the ROI on.\n",
    "#    x     = The x-coordinate of the upper left corner of the rectangle.\n",
    "#    y     = The y-coordinate of the upper left corner of the rectangle.\n",
    "#    h     = The width of the rectangle.\n",
    "#    w     = The height of the rectangle.\n",
    "#   roi_contour, roi_hierarchy = pcv.roi.rectangle(5, 90, 200, 390, img1) \n",
    "#                                                  |______________|\n",
    "#                                            adjust these four values\n",
    "roi_contour, roi_hierarchy = pcv.roi.rectangle(img=img1, x=6, y=90, h=200, w=390)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional): Get the size of the marker. First make a region of interest around one of \n",
    "# the toughspots. Then use `report_size_marker_area`. \n",
    "marker_contour, marker_hierarchy = pcv.roi.rectangle(img=img1, x=52, y=135, h=25, w=25)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   img - RGB or grayscale image to plot the marker object on \n",
    "#   roi_contour = A region of interest contour \n",
    "#   roi_hierarchy = A region of interest contour heirarchy \n",
    "#   marker = 'define' (default) or 'detect', if 'define' then you set an area, if 'detect'\n",
    "#            it means you want to detect within an area \n",
    "#   objcolor = Object color is 'dark' (default) or 'light', is the marker darker or lighter than \n",
    "#               the background?\n",
    "#   thresh_channel = 'h', 's', 'v' for hue, saturation, or value. Default set to None. \n",
    "#   thresh = Binary threshold value (integer), default set to None \n",
    "analysis_images = pcv.report_size_marker_area(img=img1, roi_contour=marker_contour, \n",
    "                                              roi_hierarchy=marker_hierarchy, marker='detect', \n",
    "                                              objcolor='light', thresh_channel='v', thresh=230)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep objects that overlap with the ROI\n",
    "\n",
    "# Inputs:\n",
    "#    img            = img to display kept objects\n",
    "#    roi_contour    = contour of roi, output from any ROI function\n",
    "#    roi_hierarchy  = contour of roi, output from any ROI function\n",
    "#    object_contour = contours of objects, output from pcv.find_objects function\n",
    "#    obj_hierarchy  = hierarchy of objects, output from pcv.find_objects function\n",
    "#    roi_type       = 'partial' (default, for partially inside the ROI), 'cutto', or \n",
    "#                     'largest' (keep only largest contour)\n",
    "roi_objects, roi_obj_hierarchy, kept_mask, obj_area = pcv.roi_objects(img=img1, roi_contour=roi_contour, \n",
    "                                                                      roi_hierarchy=roi_hierarchy,\n",
    "                                                                      object_contour=id_objects, \n",
    "                                                                      obj_hierarchy=obj_hierarchy, \n",
    "                                                                      roi_type='partial')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if all of the plants fall completely within the bounds of an image \n",
    "# or if it touches the edge. Used for QC. \n",
    "\n",
    "# Inputs:\n",
    "#   mask = Binary mask \n",
    "in_bounds = pcv.within_frame(mask=kept_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function take a image with multiple contours and\n",
    "# clusters them based on user input of rows and columns\n",
    "\n",
    "# Inputs:\n",
    "#    img               = An RGB or grayscale image\n",
    "#    roi_objects       = object contours in an image that are needed to be clustered.\n",
    "#    roi_obj_hierarchy = object hierarchy\n",
    "#    nrow              = number of rows to cluster (this should be the approximate  number of \n",
    "#                        desired rows in the entire image even if there isn't a literal row of plants)\n",
    "#    ncol              = number of columns to cluster (this should be the approximate number of \n",
    "#                        desired columns in the entire image even if there isn't a literal row of plants)\n",
    "#    show_grid         = if True then the grid is drawn on the image, default show_grid=False\n",
    "clusters_i, contours, hierarchies = pcv.cluster_contours(img=img1, roi_objects=roi_objects, \n",
    "                                                         roi_obj_hierarchy=roi_obj_hierarchy, \n",
    "                                                         nrow=4, ncol=6, \n",
    "                                                         show_grid=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: For debugging or for making figures \n",
    "\n",
    "# The image is relatively small, decrease the global line thickness parameter \n",
    "pcv.params.line_thickness = 2\n",
    "\n",
    "# Plot to visualize what pieces of plant got grouped together.\n",
    "\n",
    "# Inputs:\n",
    "#   img - RGB or grayscale image data for plotting\n",
    "#   grouped_contour_indices - Indices for grouping contours\n",
    "#   roi_objects - object contours in an image that are needed to be clustered.\n",
    "#   roi_obj_hierarchy - object hierarchy\n",
    "#   nrow - Optional, number of rows. If changed from default, grid gets plot. \n",
    "#   ncol - Optional, number of columns. If changed from default, grid gets plot. \n",
    "cluster_img = pcv.visualize.clustered_contours(img=img1, grouped_contour_indices=clusters_i, \n",
    "                                                roi_objects=contours,\n",
    "                                                roi_obj_hierarchy=hierarchies)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The pcv.cluster_contours function uses another PlantCV function\n",
    "# that returns a random list of RGB color values equally spaces\n",
    "# across a rainbow color spectrum. This function can be useful \n",
    "# when a color palette is needed \n",
    "\n",
    "# Inputs:\n",
    "#   num - An integer greater than or equal to 1. If num=1 then \n",
    "#         a random color is returned \n",
    "rand_colors = pcv.color_palette(num=5)\n",
    "print(rand_colors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function takes clustered contours and splits them into multiple images,\n",
    "# also does a check to make sure that the number of inputted filenames matches the number\n",
    "# of clustered contours. If no filenames are given then the objects are just numbered\n",
    "\n",
    "# Inputs:\n",
    "#    img                     = ideally a masked RGB image.\n",
    "#    grouped_contour_indexes = output of cluster_contours, indexes of clusters of contours\n",
    "#    contours                = contours to cluster, output of cluster_contours\n",
    "#    hierarchy               = object hierarchy\n",
    "#    outdir                  = directory for output images\n",
    "#    file                    = the name of the input image to use as a base name , output of filename from read_image function\n",
    "#    filenames               = input txt file with list of filenames in order from top to bottom left to right (likely list of genotypes)\n",
    "\n",
    "# Set global debug behavior to None (default), \"print\" (to file), or \"plot\" (Jupyter Notebooks or X11)\n",
    "# Un-comment the line below to see the split up contours print to the output directory \n",
    "#pcv.params.debug = \"print\"\n",
    "\n",
    "out = args.outdir\n",
    "\n",
    "# If you have a list of treatments, genotypes, etc. You would input a .txt file with them to help save\n",
    "# the contours by names, add it to the options class and then add filenames=names to the \n",
    "# splitimg function below.  \n",
    "output_path = pcv.cluster_contour_splitimg(rgb_img=img1, grouped_contour_indexes=clusters_i, contours=contours, \n",
    "                                           hierarchy=hierarchies, outdir=out, file=filename, filenames=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a PlantCV function is based on code contributed by Suxing Liu, Arkansas State University.\n",
    "For more information see [https://github.com/lsx1980/Leaf_count](https://github.com/lsx1980/Leaf_count).\n",
    "This function uses the watershed algorithm to detect boundary of objects.\n",
    "Needs a mask file which specifies area which is object is white, and background is black.\n",
    "Requires cv2 version 3.0+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in one of the isolated plant images \n",
    "single_plant, plant_path, plant_filename = pcv.readimage(filename='./original_image_8_p8.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another option is to use multi_roi\n",
    "\n",
    "# Create multiple ROIs on the same image:  \n",
    "# Used to define multiple regions of interest in the same image. Users can either specify a\n",
    "# starting coordinate (`coord`), number of rowsand columns, and spacing to create a grid of ROIs,\n",
    "# or a custom list of coordinates that specify the centers of the ROIs. Providing a custom list \n",
    "# of coordinates (list of tuples) is useful for missing plants or any arrangement that isn't \n",
    "# a perfect grid. Returns lists of contours and hierarchies that can be used in downstream steps. \n",
    "\n",
    "#     Inputs\n",
    "#     img            = Input image data.\n",
    "#     coord          = Two-element tuple of the center of the top left object.\n",
    "#     radius         = Radius of ROIs.\n",
    "#     spacing        = Two-element tuple of the horizontal and vertical spacing between ROIs.\n",
    "#     nrows          = Number of rows in ROI layout.\n",
    "#     ncols          = Number of columns in ROI layout.\n",
    "\n",
    "# Make a grid of ROIs \n",
    "rois1, roi_hierarchy1 = pcv.roi.multi(img=img1, coord=(25,120), radius=20, spacing=(70, 70), nrows=3, ncols=6)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The image is relatively small so decrease line_thickness parameter (default = 5)\n",
    "pcv.params.line_thickness = 2\n",
    "\n",
    "# Specify a list of coordinates of desired ROIs \n",
    "rois2, roi_hierarchy2 = pcv.roi.multi(img=img1, coord=[(25,120), (165,260), (310, 260)], radius=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "img_copy = np.copy(img1)\n",
    "\n",
    "# Analyze each plant using the ROI's created by using the grid setup for pcv.roi.multi\n",
    "\n",
    "for i in range(0, len(rois1)):\n",
    "    roi = rois1[i]\n",
    "    hierarchy = roi_hierarchy1[i]\n",
    "    # Filter objects by ROI \n",
    "    filtered_contours, filtered_hierarchy, filtered_mask, filtered_area = pcv.roi_objects(\n",
    "        img=img1, roi_type=\"partial\", roi_contour=roi, roi_hierarchy=hierarchy, object_contour=roi_objects, \n",
    "        obj_hierarchy=roi_obj_hierarchy)\n",
    "\n",
    "    # Combine objects together in each plant     \n",
    "    plant_contour, plant_mask = pcv.object_composition(img=img_copy, contours=filtered_contours, hierarchy=filtered_hierarchy)        \n",
    "\n",
    "    # Analyze the shape of each plant \n",
    "    analysis_images = pcv.analyze_object(img=img_copy, obj=plant_contour, mask=plant_mask)\n",
    "\n",
    "    # Save the image with shape characteristics \n",
    "    img_copy = analysis_images\n",
    "\n",
    "    # Print out a text file with shape data for each plant in the image \n",
    "    pcv.print_results(filename = 'prefix_' + str(i) + '.txt')\n",
    "    # Clear the measurements stored globally into the Ouptuts class\n",
    "    pcv.outputs.clear()\n",
    "\n",
    "# Plot out the image with shape analysis on each plant in the image \n",
    "pcv.plot_image(img_copy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To view and/or download the text file output (saved in JSON format)...\n",
    "1) To see the text file with data that got saved out, click “File” tab in top left corner.\n",
    "2) Click “Open…”\n",
    "3) Open the multi-plant text files \n",
    "\n",
    "Check out documentation on how to [convert JSON](https://plantcv.readthedocs.io/en/latest/tools/#convert-output-json-data-files-to-csv-tables) format output into table formatted output. Depending on the analysis steps a PlantCV user may have two CSV files (single value traits and multivalue traits). \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
