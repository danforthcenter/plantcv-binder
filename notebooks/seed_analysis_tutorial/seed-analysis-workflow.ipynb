{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f398b49",
   "metadata": {},
   "source": [
    "# Quinoa Seed Analysis Tutorial\n",
    "\n",
    "This is a full workflow that shows methods for counting and analyzing the shape and color of seeds. Similar methods should work for other types of seeds."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25268a22",
   "metadata": {},
   "source": [
    "# Section 1: Importing libraries and image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "acc77c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the notebook display method\n",
    "# inline = embedded plots, notebook = interactive plots\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65e727bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "\n",
    "%matplotlib notebook\n",
    "import os\n",
    "import argparse\n",
    "import matplotlib\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "from plantcv import plantcv as pcv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2de8ecff",
   "metadata": {},
   "source": [
    "## Input variables\n",
    "\n",
    "The options class mimics the workflow command-line argument parser that is used for workflow parallelization. Using it while developing a workflow in Jupyter makes it easier to convert the workflow to a script later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f00798e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input image into self.image (include file path if image is not in \n",
    "# the same folder as jupyter notebook)\n",
    "\n",
    "# Set self.debug to \"plot\" so that image outputs for each step is shown\n",
    "# once cell is run in jupyter notebooks (recommended)\n",
    "\n",
    "class options:\n",
    "    def __init__(self):        \n",
    "        self.image = \"./img/quinoa_seeds.jpg\"\n",
    "        self.debug = \"plot\"\n",
    "        self.writeimg = False\n",
    "        self.result = \"seed_analysis_results\"\n",
    "        self.outdir = \".\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2b487cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get options\n",
    "args = options()\n",
    "\n",
    "# Set debug to the global parameter\n",
    "pcv.params.debug = args.debug\n",
    "\n",
    "# Set plotting size (default = 100)\n",
    "pcv.params.dpi = 100\n",
    "\n",
    "# Increase text size and thickness to make labels clearer\n",
    "# (size may need to be altered based on original image size)\n",
    "pcv.params.text_size = 10\n",
    "pcv.params.text_thickness = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b3179d",
   "metadata": {},
   "source": [
    "## Read the input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88c3dc7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Failed to open ./img/quinoa_seeds.jpg",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-bbd26c4a14f4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#   filename = Image file to be read in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#   mode     = How to read in the image; either 'native' (default), 'rgb', 'gray', or 'csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadimage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/REU2021/plantcv_new/plantcv/plantcv/readimage.py\u001b[0m in \u001b[0;36mreadimage\u001b[0;34m(filename, mode)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mimg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mfatal_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Failed to open \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0;31m# Split path from filename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/REU2021/plantcv_new/plantcv/plantcv/fatal_error.py\u001b[0m in \u001b[0;36mfatal_error\u001b[0;34m(error)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \"\"\"\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to open ./img/quinoa_seeds.jpg"
     ]
    }
   ],
   "source": [
    "# Inputs:\n",
    "#   filename = Image file to be read in \n",
    "#   mode     = How to read in the image; either 'native' (default), 'rgb', 'gray', or 'csv'\n",
    "img, path, filename = pcv.readimage(filename=args.image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7af70a",
   "metadata": {},
   "source": [
    "# Section 2: Segmenting plant from background and identifying plant object(s)\n",
    "\n",
    "* Requires successful import of image\n",
    "* See Threshold Tools Tutorial tutorial for other functions that can be used to create a binary mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d33e0a",
   "metadata": {},
   "source": [
    "## Visualize colorspaces\n",
    "\n",
    "The visualization tool converts the color image into HSV and LAB colorspaces and displays the grayscale channels in a matrix so that they can be visualized simultaneously. The idea is to select a channel that maximizes the difference between the plant and the background pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9065b963",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   rbg_img      = original image\n",
    "#   original_img = whether to include the original RGB images in the display: True (default) or False\n",
    "colorspace_img = pcv.visualize.colorspaces(rgb_img=img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf530c4",
   "metadata": {},
   "source": [
    "## Crop image\n",
    "\n",
    "Cropping out aspects of the image that may interfere with the binary mask makes it easier to isolate plant material from background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5907d84",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   x = top left x-coordinate\n",
    "#   y = top left y-coordinate\n",
    "#   h = height of final cropped image\n",
    "#   w = width of final cropped image\n",
    "img = pcv.crop(img=img, x=1300, y=750, h=1750, w=2100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0b9cc5",
   "metadata": {},
   "source": [
    "## Convert the color image to grayscale\n",
    "\n",
    "Converts the input color image into the LAB colorspace and returns the B (blue-yellow) channel as a grayscale image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4436b613",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   rbg_img - original image\n",
    "#   channel - desired colorspace ('l', 'a', or 'b')\n",
    "b_img = pcv.rgb2gray_lab(rgb_img=img, channel='b')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affd8573",
   "metadata": {},
   "source": [
    "## Visualize the distribution of grayscale values\n",
    "\n",
    "A histogram can be used to visualize the distribution of values in an image. The histogram can aid in the selection of a threshold value.\n",
    "\n",
    "For this image, the large peak between 125-130 are from the darker background pixels. The smaller peak between 150-160 are the lighter seed pixels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1afdeffb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   img         = gray image in selected colorspace\n",
    "#   mask        = None (default), or mask\n",
    "#   bins        = 100 (default) or number of desired number of evenly spaced bins\n",
    "#   lower-bound = None (default) or minimum value on x-axis\n",
    "#   upper-bound = None (default) or maximum value on x-axis\n",
    "#   title       = None (default) or custom plot title\n",
    "#   hist_data   = False (default) or True (if frequency distribution data is desired)\n",
    "hist = pcv.visualize.histogram(img=b_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831d7c01",
   "metadata": {},
   "source": [
    "## Threshold the grayscale image\n",
    "Use a threshold function (binary in this case) to segment the grayscale image into plant (white) and background (black) pixels. Using the histogram above, a threshold point between 130-150 will segment the plant and background peaks. Because the seeds are the lighter pixels in this image, use object_type=\"light\" to do a traditional threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3065640",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   gray_img    = black and white image created from selected colorspace\n",
    "#   threshold   = cutoff pixel intensity value (all pixels below value will become black, all above will become white)\n",
    "#   max_value   = maximum pixel value\n",
    "#   object_type = 'dark' or 'light' depending on if seeds are darker or lighter than background\n",
    "b_thresh = pcv.threshold.binary(gray_img=b_img, threshold=140, max_value=255, object_type='light')\n",
    "#                                                          ^                                 ^\n",
    "#                                                          |                                 |\n",
    "#                                                  change this value                  change this value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5530bcab",
   "metadata": {},
   "source": [
    "## Remove small background noise\n",
    "\n",
    "Thresholding mostly labeled plant pixels white but also labeled small regions of the background white. The fill function removes \"salt\" noise from the background by filtering white regions by size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6b2810",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   bin_img - binary mask image\n",
    "#   size - maximum size for objects that should be filled in as background (non-plant) pixels\n",
    "b_fill = pcv.fill(bin_img=b_thresh, size=300)\n",
    "#                                         ^\n",
    "#                                         |\n",
    "#                                 change this value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98e85e9",
   "metadata": {},
   "source": [
    "# Section 3: Count and Analyze Seeds\n",
    "\n",
    "* Need a completed binary mask"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022afc78",
   "metadata": {},
   "source": [
    "## Identify simple seed objects\n",
    "\n",
    "The binary mask can be used to find objects, or contours, each of which will outline a seed. Unlike the PlantCV find_objects function, this uses findContours from OpenCV with the input cv2.RETR_EXTERNAL to ignore layered contours. The output from this step can be used to count seeds, but CANNOT be used as input for shape and color analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3551a631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   mask = binary mask with extra noise filled in\n",
    "objects = cv2.findContours(b_fill, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea12e9b",
   "metadata": {},
   "source": [
    "## Count seeds\n",
    "\n",
    "Count the number of seeds (simple objects) by accessing the number of values stores in the second item of the object list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f6e509",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find number of seeds\n",
    "\n",
    "# Inputs:\n",
    "#    contours = list of contours\n",
    "number_seeds = len(objects[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2619d02",
   "metadata": {},
   "source": [
    "## Identify seed objects for shape and color analysis\n",
    "\n",
    "For shape and color analysis, we need to use find_objects from PlantCV to get the objects and object hierarchy that we need as inputs in the following analyses. OpenCV findContours and PlantCV find_objects do not behave in the same way or provide the same outputs, which is why we must identify objects twice in this workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b821e88b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   img  = rgb image\n",
    "#   mask = binary mask\n",
    "objects2, obj_hierarchy = pcv.find_objects(img=img, mask=b_fill)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73576ccd",
   "metadata": {},
   "source": [
    "## Measure each seed\n",
    "\n",
    "To measure each seed, iterate over the objects (which occur when obj_hierarchy[0][i][3] == -1). For each object, the following steps are done:\n",
    "\n",
    "1. Contours are consolidated, so that all contours that correspond to one seed are compiled into a single object and mask.\n",
    "2. Analyze seed shape\n",
    "3. Analyze seed color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5558240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the RGB image for shape analysis annotations\n",
    "# Inputs:\n",
    "#   img = image\n",
    "shape_img = np.copy(img)\n",
    "\n",
    "# Turn off plot debugging\n",
    "pcv.params.debug = None\n",
    "\n",
    "# Interate through all objects in objects2 and do a shape and color analysis\n",
    "# for i in range(0, len(objects2)): \n",
    "# The loop above takes up too much memory for binder, but ideally you'd loop over every seed \n",
    "\n",
    "# For demonstration purposes, we can loop through the first 15 objects\n",
    "for i in range(0, 15):\n",
    "    # Check to see if the object has an offshoot in the hierarchy\n",
    "    if obj_hierarchy[0][i][3] == -1:\n",
    "        # Create an object and a mask for one object\n",
    "        #\n",
    "        # Inputs:\n",
    "        #   img - rgb image\n",
    "        #   contours - list entry i in objects2\n",
    "        #   hierarchy - np.array of obj_hierarchy[0][1]\n",
    "        seed, seed_mask = pcv.object_composition(img=img, contours=[objects2[i]], hierarchy=np.array([[obj_hierarchy[0][i]]]))\n",
    "        \n",
    "        # Analyze shape of each seed\n",
    "        #\n",
    "        # Inputs:\n",
    "        #   img - rgb image\n",
    "        #   obj - seed\n",
    "        #   mask - mask created of single seed\n",
    "        #   label - label for each seed in image\n",
    "        shape_img = pcv.analyze_object(img=shape_img, obj=seed, mask=seed_mask, label=f\"seed{i}\")\n",
    "        \n",
    "        # Analyze color of each seed\n",
    "        #\n",
    "        # Inputs:\n",
    "        #   img - rgb image\n",
    "        #   obj - seed\n",
    "        #   hist_plot_type - 'all', or None for no histogram plot\n",
    "        #   label - 'default'      \n",
    "        color_img = pcv.analyze_color(rgb_img=img, mask=b_fill, hist_plot_type=None, label=\"default\")\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2257018",
   "metadata": {},
   "source": [
    "## Visualize shape analysis of seeds\n",
    "\n",
    "Since debugging was turned off during the for loop, as plotting all analysis results significantly slows down the analysis, we can plot the final shape and color analyses to ensure that the results look correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f384a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   img = image for shape analysis\n",
    "pcv.plot_image(img=shape_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e1301d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   img = image for color analysis\n",
    "pcv.plot_image(img=color_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ea7821",
   "metadata": {},
   "source": [
    "## Save results\n",
    "\n",
    "During analysis, measurements are stored in the background in the outputs recorder.\n",
    "\n",
    "This example includes image analysis for 'area', 'convex_hull_area', 'solidity', 'perimeter', 'width', 'height', 'longest_path', 'center_of_mass, 'convex_hull_vertices', 'object_in_frame', 'ellipse_center', 'ellipse_major_axis', 'ellipse_minor_axis', 'ellipse_angle', 'ellipse_eccentricity' using anayze_object and color analysis using analyze_color.\n",
    "\n",
    "Here, results are saved to a CSV file for easy viewing, but when running workflows in parallel, save results as \"json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e077997d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inputs:\n",
    "#   filename  = filename for saving results\n",
    "#   outformat = output file format: \"json\" (default) hierarchical format or \"csv\" tabular format\n",
    "pcv.outputs.save_results(filename=args.result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
